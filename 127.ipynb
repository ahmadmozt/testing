{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "127.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZyRM2IQCIZn7"
      },
      "source": [
        "# Propose d\n",
        "### Data size : 24 x 24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hXEKQMHdlHwt"
      },
      "source": [
        "### Mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBeaIjy6u6si",
        "colab_type": "code",
        "outputId": "616c96f4-3adc-41d7-ca31-7806709e7a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bk1Kp1GflHxA"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ShiQewe7lHxF",
        "outputId": "9c812c3a-4e08-477c-9efe-23de77714019",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import os\n",
        "#import cv2\n",
        "import time # for time spend callbacks\n",
        "import pickle\n",
        "import statistics # mean report time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import TensorBoard, Callback\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Activation, Dropout, Dense, \\\n",
        "                        concatenate, AveragePooling2D, GlobalAveragePooling2D, \\\n",
        "                        Flatten, BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "from keras.initializers import glorot_uniform, Constant"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPZrJbHfFDuk",
        "colab_type": "text"
      },
      "source": [
        "### Dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0805hQ95M4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_dict = {\n",
        "    'colab':(\"drive/My Drive/Colab Notebooks/dataset/80-20/80-20-24-no-aug-in-test.pkl\",\n",
        "             \"drive/My Drive/Colab Notebooks\"),\n",
        "    'ultrabook':(\"../../data/extraction/2-release/samples-ext/samples-train-test-24-2-class.pkl\",\n",
        "            \"../../warehouse\")\n",
        "}\n",
        "\n",
        "optimizer_dict = {\n",
        "    'adam' : 'adam',\n",
        "    'SGD' : 'SGD',\n",
        "    'SGD_param' : SGD(lr=1e-2, momentum=0.9, nesterov=False)\n",
        "}\n",
        "\n",
        "init_dict = {\n",
        "    'kernel' : glorot_uniform(),\n",
        "    'bias' : Constant(value = 0.2)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6RvhqA_7IZol"
      },
      "source": [
        "## Hyperparameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BuG8g5zbIZor",
        "scrolled": false,
        "outputId": "dff4b99b-d208-4d16-884a-6115698ed844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class HyperParameter:\n",
        "    def __init__(self):\n",
        "        self._path_pickle, self._path_save = path_dict['colab']\n",
        "        \n",
        "        self._name = \"127\"\n",
        "        self._img_size = 24\n",
        "        self._running_numbers = 6\n",
        "        \n",
        "        self._epochs = 50\n",
        "        self._batchs = 128\n",
        "        self._optimizer = optimizer_dict['adam']\n",
        "        \n",
        "        print('HyperParameter set')\n",
        "\n",
        "if __name__=='__main__':\n",
        "    hp = HyperParameter()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HyperParameter set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1fm0QG6mIZpC"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nE1ZEa_IZpG",
        "outputId": "952ad459-49b2-4f9c-d92c-814c45c136ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "class LoadData(HyperParameter):\n",
        "    \n",
        "    def loading_img(self, path_data):\n",
        "        print(f'[INFO] Load char {path_name}')\n",
        "        \n",
        "        path_name = os.path.basename(path_data)\n",
        "        loaded_images = []\n",
        "        loaded_labels = []\n",
        "        \n",
        "        self.__class_labels = sorted(os.listdir(path_data)) # Label\n",
        "        self.__number_of_class = len(self.__class_labels) # Amount\n",
        "\n",
        "        for class_label in tqdm(self.__class_labels):\n",
        "            class_index = self.__class_labels.index(class_label) # Get index\n",
        "            path_img = os.path.join(path_data, class_label)\n",
        "\n",
        "            for img_name in os.listdir(path_img):\n",
        "                img = cv2.imread(\n",
        "                    os.path.join(path_img, img_name), cv2.IMREAD_GRAYSCALE) # Grayscale\n",
        "                loaded_images.append(img)\n",
        "                loaded_labels.append(class_index)\n",
        "                \n",
        "        print(f'jumlah data : {len(loaded_images)} data')\n",
        "\n",
        "        return loaded_images, loaded_labels\n",
        "\n",
        "    def executing_load(self):\n",
        "        \"\"\"Load characters from directories\"\"\"\n",
        "        \n",
        "        self.__x_train, self.__y_train = self.loading_img(self._path_train)\n",
        "        self.__x_val, self.__y_val = self.loading_img(self._path_val)\n",
        "        \n",
        "        print(f'\\nClass : {self.__class_labels}')\n",
        "        print(f'\\nNumber of class : {self.__number_of_class} class')\n",
        "        \n",
        "    def loading_pickle(self):\n",
        "        \"\"\"Load character from pickle file\"\"\"\n",
        "        \n",
        "        path_pickle = self._path_pickle\n",
        "        \n",
        "        p_in = open(path_pickle, \"rb\")\n",
        "        loaded_pickle = pickle.load(p_in)\n",
        "        p_in.close()\n",
        "        \n",
        "        self.__x_train = loaded_pickle[0]\n",
        "        self.__y_train = loaded_pickle[1]\n",
        "        self.__x_test = loaded_pickle[2]\n",
        "        self.__y_test = loaded_pickle[3]\n",
        "        self.__number_of_class = loaded_pickle[4]\n",
        "        self.__class_labels = loaded_pickle[5]\n",
        "        \n",
        "        print(f'jumlah data train : {len(self.__x_train)} gambar dan {len(self.__y_train)} label')\n",
        "        print(f'jumlah data val : {len(self.__x_test)} gambar dan {len(self.__y_test)} label')\n",
        "        print(f'jumlah class : {self.__number_of_class}')\n",
        "        print(f'class : {self.__class_labels}')\n",
        "        \n",
        "    @property\n",
        "    def x_train(self):\n",
        "        return self.__x_train\n",
        "    @property\n",
        "    def y_train(self):\n",
        "        return self.__y_train\n",
        "    @property\n",
        "    def x_test(self):\n",
        "        return self.__x_test\n",
        "    @property\n",
        "    def y_test(self):\n",
        "        return self.__y_test\n",
        "    @property\n",
        "    def number_of_class(self):\n",
        "        return self.__number_of_class\n",
        "    @property\n",
        "    def classes(self):\n",
        "        return self.__class_labels\n",
        "    \n",
        "load = LoadData()\n",
        "#load.executing_load()\n",
        "load.loading_pickle()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HyperParameter set\n",
            "jumlah data train : 14400 gambar dan 14400 label\n",
            "jumlah data val : 3600 gambar dan 3600 label\n",
            "jumlah class : 36\n",
            "class : ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "j9pq9832IZpZ"
      },
      "source": [
        "### Train and Test samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K9Pq_cOqIZpd",
        "outputId": "92821fe9-ad73-4d8c-9584-d310690494aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "index = 3\n",
        "print('train label {}, shape {}'.format(load.y_train[index], load.x_train[index].shape))\n",
        "print('test label {}, shape {}'.format(load.y_test[index], load.x_test[index].shape))\n",
        "\n",
        "plt.subplot(121), plt.imshow(load.x_train[index], 'gray'), plt.title('train')\n",
        "plt.subplot(122), plt.imshow(load.x_test[index], 'gray'), plt.title('test')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train label 18, shape (24, 24)\n",
            "test label 16, shape (24, 24)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADHCAYAAAAAoQhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1W_6PVVkIZpn"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "21tf3L6hIZpq",
        "outputId": "cccd27db-0d62-4f01-dc38-c405b67d2aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "class Preprocessing(HyperParameter):\n",
        "    def __init__(self, x_train, y_train, x_test, y_test, num_class):\n",
        "        HyperParameter.__init__(self)\n",
        "        self.__x_train = x_train\n",
        "        self.__y_train = y_train\n",
        "        self.__x_test = x_test\n",
        "        self.__y_test = y_test\n",
        "        self.__num_class = num_class\n",
        "\n",
        "    def reshape_normalize(self, x):\n",
        "        x = np.array(x).reshape(-1, self._img_size, self._img_size, 1)\n",
        "        x = x.astype('float32')\n",
        "        x /= 255\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def collecting_shape(self, feature):\n",
        "        feature_shape = feature[0].shape # shape\n",
        "        print('image shape {}'.format(feature_shape))\n",
        "        \n",
        "        return feature_shape\n",
        "    \n",
        "    def binary_class_matrix(self, y, number_class):\n",
        "        y = to_categorical(y, number_class)\n",
        "        \n",
        "        print('class binnerization succeed')\n",
        "        \n",
        "        return y\n",
        "    \n",
        "    def get_reshape_matrix(self):\n",
        "        print('[INFO] Preprocessing: reshape, normalize, binary_class_matrix...')\n",
        "        \n",
        "        self.__x_train_reshape = self.reshape_normalize(self.__x_train)\n",
        "        self.__y_train_reshape = self.binary_class_matrix(self.__y_train, self.__num_class)\n",
        "        \n",
        "        print('feature train shape {}'.format(self.__x_train_reshape.shape))\n",
        "        \n",
        "        self.__x_test_reshape = self.reshape_normalize(self.__x_test)\n",
        "        self.__y_test_reshape = self.binary_class_matrix(self.__y_test, self.__num_class)\n",
        "        \n",
        "        print('feature test shape {}'.format(self.__x_test_reshape.shape))\n",
        "        \n",
        "        self.__image_shape = self.collecting_shape(self.__x_test_reshape)\n",
        "        \n",
        "        print('preprocessing done')\n",
        "        \n",
        "    @property\n",
        "    def x_train(self):\n",
        "        return self.__x_train_reshape\n",
        "    @property\n",
        "    def y_train(self):\n",
        "        return self.__y_train_reshape\n",
        "    @property\n",
        "    def x_test(self):\n",
        "        return self.__x_test_reshape\n",
        "    @property\n",
        "    def y_test(self):\n",
        "        return self.__y_test_reshape\n",
        "    @property\n",
        "    def image_shape(self):\n",
        "        return self.__image_shape\n",
        "    \n",
        "pp = Preprocessing(load.x_train, load.y_train,\n",
        "                       load.x_test, load.y_test,\n",
        "                       load.number_of_class)\n",
        "pp.get_reshape_matrix()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HyperParameter set\n",
            "[INFO] Preprocessing: reshape, normalize, binary_class_matrix...\n",
            "class binnerization succeed\n",
            "feature train shape (14400, 24, 24, 1)\n",
            "class binnerization succeed\n",
            "feature test shape (3600, 24, 24, 1)\n",
            "image shape (24, 24, 1)\n",
            "preprocessing done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gbL3JsT7IZqB"
      },
      "source": [
        "## Time Counter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7uwRmn8iIZqD",
        "colab": {}
      },
      "source": [
        "class TimeHistory(Callback):\n",
        "    def on_train_begin(self, logs = {}):\n",
        "        self.times = []\n",
        "    def on_epoch_begin(self, batch, logs = {}):\n",
        "        self.epoch_time_start = time.time()\n",
        "    def on_epoch_end(self, batch, logs = {}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EXaqcKLxIZqN"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xFE_SRtN68OR",
        "outputId": "8a4609d7-947c-41d5-cc11-0402a0288c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "class ConvolutionalNetworks(HyperParameter):\n",
        "    def __init__(self, x_train, y_train, x_test, y_test, input_shape, num_classes):\n",
        "        HyperParameter.__init__(self)\n",
        "        self.__x_train = x_train\n",
        "        self.__y_train = y_train\n",
        "        self.__x_test = x_test\n",
        "        self.__y_test = y_test\n",
        "        self.__num_classes = num_classes\n",
        "        self.X_input = Input(shape=input_shape)\n",
        "\n",
        "        self._results = []\n",
        "        self._average_acc = []\n",
        "\n",
        "    def setting_path(self):\n",
        "        path_save = os.path.join(self._path_save, self._name)\n",
        "        if not os.path.exists(path_save):\n",
        "            os.mkdir(path_save)\n",
        "\n",
        "        self._path_logs = os.path.join(path_save, \"logs\")\n",
        "        self._path_model = os.path.join(path_save, \"models\")\n",
        "        self._path_history = os.path.join(path_save, \"histories\")\n",
        "        self._path_recordings = os.path.join(path_save, \"recordings\")\n",
        "\n",
        "        path_list = [self._path_logs,\n",
        "                     self._path_model,\n",
        "                     self._path_history,\n",
        "                     self._path_recordings]\n",
        "        \n",
        "        for path in path_list:\n",
        "            if not os.path.exists(path):\n",
        "                os.mkdir(path)\n",
        "                print(f'Path {path} created')\n",
        "\n",
        "    def saving_results(self, model, histories, recordings, name):\n",
        "        model.save(os.path.join(self._path_model, \"m-{}.h5\".format(name)))\n",
        "\n",
        "        p_out = open(os.path.join(self._path_history, \"h-{}.pkl\".format(name)), \"wb\")\n",
        "        pickle.dump(histories, p_out)\n",
        "        p_out.close()\n",
        "\n",
        "        p_out = open(os.path.join(self._path_recordings, \"r-{}.pkl\".format(name)), \"wb\")\n",
        "        pickle.dump(recordings, p_out)\n",
        "        p_out.close()\n",
        "\n",
        "        print(f'{name} saved\\n')\n",
        "        \n",
        "    def conv(self, X, filter_numbers, filter_size, strides, paddings):\n",
        "        X = Conv2D(filter_numbers, (filter_size, filter_size), strides=strides, padding=paddings)(X)\n",
        "        \n",
        "        return X\n",
        "    \n",
        "    def conv_bn(self, X, filter_numbers, filter_size, strides, paddings):\n",
        "        X = Conv2D(filter_numbers, (filter_size, filter_size), strides=strides, padding=paddings)(X)\n",
        "        X = BatchNormalization()(X)\n",
        "        \n",
        "        return X\n",
        "    \n",
        "    def conv_act(self, X, filter_numbers, filter_size, strides, paddings):\n",
        "        X = Conv2D(filter_numbers, (filter_size, filter_size), strides=strides, padding=paddings)(X)\n",
        "        X = Activation('relu')(X)\n",
        "        \n",
        "        return X\n",
        "\n",
        "    def conv__bn_act(self, X, filter_numbers, filter_size, strides, paddings):\n",
        "        X = Conv2D(filter_numbers, (filter_size, filter_size), strides=strides, padding=paddings)(X)\n",
        "        X = BatchNormalization()(X)\n",
        "        X = Activation('relu')(X)\n",
        "        \n",
        "        return X\n",
        "    \n",
        "    def res_conv_block(self, X, filters, filter_size, strides, paddings=None):\n",
        "        X_shortcut = X\n",
        "        \n",
        "        X = self.conv_bn(X, filters, filter_size, strides, paddings)\n",
        "        X = self.conv_bn(X, filters, filter_size, 1, paddings)\n",
        "        \n",
        "        X_shortcut = self.conv(X_shortcut, filters, 1, strides, paddings)\n",
        "        \n",
        "        merged = Add()([X, X_shortcut])\n",
        "        \n",
        "        return merged\n",
        "    \n",
        "    def res_idn_block(self, X, filters, filter_size, strides, paddings=None):\n",
        "        X_shortcut = X\n",
        "        \n",
        "        X = self.conv_bn(X, filters, filter_size, strides, paddings)\n",
        "        X = self.conv_bn(X, filters, filter_size, strides, paddings)\n",
        "        \n",
        "        merged = Add()([X, X_shortcut])\n",
        "        \n",
        "        return merged\n",
        "    \n",
        "    def wide_conv_block(self, X, filter_numbers, filter_size, strides, paddings):\n",
        "        X_shortcut = X\n",
        "        \n",
        "        X = self.conv_act(X, filter_numbers, filter_size, strides, paddings)\n",
        "        X = self.conv_act(X, filter_numbers, filter_size, 1, paddings)\n",
        "\n",
        "        X_shortcut = self.conv(X_shortcut, filter_numbers, filter_size, strides, paddings)\n",
        "\n",
        "        merged = Add()([X, X_shortcut])\n",
        "        \n",
        "        return merged\n",
        "    \n",
        "    def wide_idn_block(self, X, filter_numbers, filter_size, strides, paddings):\n",
        "        X_shortcut = X\n",
        "        \n",
        "        #X = BatchNormalization()(X)\n",
        "        X = Activation('relu')(X)\n",
        "        \n",
        "        X = self.conv_act(X, filter_numbers, filter_size, strides, paddings)\n",
        "        X = self.conv(X, filter_numbers, filter_size, strides, paddings)\n",
        "        \n",
        "        merged = Add()([X, X_shortcut])\n",
        "        \n",
        "        return merged\n",
        "    \n",
        "    def incept_v1(self, X, filter_numbers, filter_size, strides, paddings):\n",
        "        conv_1x1 = self.conv_act(X, 64, 1, strides, paddings)\n",
        "        \n",
        "        conv_3x3 = self.conv_act(X, 64, 1, strides, paddings)\n",
        "        conv_3x3 = self.conv_act(conv_3x3, 96, 3, strides, paddings)\n",
        "        \n",
        "        conv_2x3x3 = self.conv_act(X, 16, 1, strides, paddings)\n",
        "        conv_2x3x3 = self.conv_act(conv_2x3x3, 48, 3, strides, paddings)\n",
        "        conv_2x3x3 = self.conv_act(conv_2x3x3, 48, 3, strides, paddings)\n",
        "        \n",
        "        pool_3x3 = MaxPool2D((3, 3), strides=(strides, strides), padding=paddings)(X)\n",
        "        pool_3x3 = self.conv_act(pool_3x3, 32, 1, strides, paddings)\n",
        "        \n",
        "        concat = concatenate([conv_1x1, conv_3x3, conv_2x3x3, pool_3x3], axis=3)\n",
        "        \n",
        "        return concat\n",
        "    \n",
        "    def incept_conv_max(self, X, filter_numbers, filter_size, strides, paddings):\n",
        "        X_conv = self.conv_act(X, filter_numbers, filter_size, strides, paddings)\n",
        "\n",
        "        X_pool = MaxPool2D((filter_size, filter_size), strides=strides, padding=paddings)(X)\n",
        "        \n",
        "        concat = concatenate([X_conv, X_pool], axis=3)\n",
        "\n",
        "        return concat\n",
        "    \n",
        "    def running_architecture(self):\n",
        "        filter_numbers = (32, 64, 128, 256)\n",
        "        dropout_numbers = np.round(np.arange(0.1, 1, 0.1), decimals=1)\n",
        "\n",
        "        snippet_name = \"max-2\"\n",
        "\n",
        "        for number in range(self._running_numbers):\n",
        "            save_name = f\"{self._name}-{snippet_name}-{number}-{int(time.time())}\"\n",
        "        \n",
        "            X = self.conv_act(self.X_input, filter_numbers[0], 3, 1, 'same')\n",
        "            X = self.incept_conv_max(X, filter_numbers[0], 3, 1, 'valid')\n",
        "\n",
        "            #X = self.conv_act(X, filter_numbers[1], 3, 1, 'same')\n",
        "            X = self.incept_v1(X, 16, 3, 1, 'same')\n",
        "            X = self.incept_conv_max(X, filter_numbers[1], 3, 2, 'valid')\n",
        "\n",
        "            X = self.conv_act(X, filter_numbers[2], 3, 1, 'same')\n",
        "            X = self.conv_act(X, filter_numbers[2], 3, 1, 'same')\n",
        "            X = MaxPool2D((3, 3), strides=(2, 2))(X)\n",
        "            \n",
        "            X = self.conv_act(X, filter_numbers[3], 3, 1, 'same')\n",
        "            X = self.conv_act(X, filter_numbers[3], 3, 1, 'same')\n",
        "            X = MaxPool2D((3, 3), strides=(1, 1), padding='valid')(X)\n",
        "            \n",
        "            X = GlobalAveragePooling2D()(X)\n",
        "\n",
        "            X = Dense(1024, name='fc')(X)\n",
        "            X = Activation('relu', name='fc_relu')(X)\n",
        "            X = Dropout(0.5, name='dropout')(X)\n",
        "\n",
        "            X = Dense(self.__num_classes, activation='softmax', name='softmax')(X)\n",
        "\n",
        "            model = Model(inputs = self.X_input,\n",
        "                          outputs = X,\n",
        "                          name = save_name)\n",
        "            model.summary()\n",
        "            model.compile(\n",
        "                loss='categorical_crossentropy',\n",
        "                optimizer=self._optimizer,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "            time_callback = TimeHistory()\n",
        "            tensorboard = TensorBoard(log_dir=os.path.join(self._path_logs, \"{}\".format(save_name)))\n",
        "\n",
        "            histories = model.fit(\n",
        "                self.__x_train, self.__y_train,\n",
        "                validation_data = (self.__x_test, self.__y_test),\n",
        "                epochs = self._epochs,\n",
        "                batch_size = self._batchs,\n",
        "                verbose = 2,\n",
        "                callbacks = [time_callback, tensorboard])\n",
        "\n",
        "            recordings = time_callback.times\n",
        "\n",
        "            test_score = model.evaluate(pp.x_test, pp.y_test)        \n",
        "            show_score = \"Test loss {:.4f}, accuracy {:.2f}%\".format(test_score[0], (test_score[1]) * 100)\n",
        "            print(show_score)\n",
        "\n",
        "            total_time = sum(recordings) # Detik\n",
        "            menit_time = total_time/60\n",
        "            recorded_mean = statistics.mean(recordings)\n",
        "            \n",
        "            print(f'\\nTotal in second = {round(total_time, 3)} seconds')\n",
        "            print(f'Total in minute = {round(menit_time, 3)} minutes')\n",
        "            train_speed = f'Time = {round(recorded_mean, 3)} second/epochs'\n",
        "            print(train_speed)\n",
        "            print()\n",
        "\n",
        "            #self.saving_results(model, histories, recordings, save_name)\n",
        "\n",
        "            self._results.append([save_name, show_score, train_speed])\n",
        "            self._average_acc.append([test_score[1]])\n",
        "\n",
        "    def reporting_results(self):\n",
        "        for report in self._results:\n",
        "            print(report)\n",
        "\n",
        "        print()\n",
        "        self._average_acc = np.round(np.mean(self._average_acc), 2)\n",
        "        \n",
        "    def showing_graph(self):\n",
        "        if keras.__version__=='2.3.1':\n",
        "            format_hist = ['accuracy', 'val_accuracy']\n",
        "        else:\n",
        "            format_hist = ['acc', 'val_acc']\n",
        "        \n",
        "        f, ax = plt.subplots() # Accuracy Graph\n",
        "        ax.plot([None] + self.__history.history[format_hist[0]], 'o-')\n",
        "        ax.plot([None] + self.__history.history[format_hist[1]], 'x-')\n",
        "        ax.legend(['Akurasi Train', 'Akurasi Validasi'], loc = 0) # loc = 0 => lokasi legend\n",
        "        ax.set_title('Akurasi dan Validasi per Epoch')\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.set_ylabel('Akurasi')\n",
        "        \n",
        "        f, ax = plt.subplots() # Loss Graph\n",
        "        ax.plot([None] + self.__history.history['loss'], 'o-')\n",
        "        ax.plot([None] + self.__history.history['val_loss'], 'x-')\n",
        "        ax.legend(['Loss Train', 'Loss Validasi'], loc = 0) # loc = 0 => lokasi legend\n",
        "        ax.set_title('Loss Train dan Validasi per Epoch')\n",
        "        ax.set_xlabel('Epoch')\n",
        "        ax.set_ylabel('Loss')\n",
        "\n",
        "cnn = ConvolutionalNetworks(pp.x_train, pp.y_train,\n",
        "                           pp.x_test, pp.y_test,\n",
        "                           pp.image_shape, load.number_of_class)\n",
        "cnn.setting_path()\n",
        "cnn.running_architecture()\n",
        "cnn.reporting_results()\n",
        "#cnn.showing_graph()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "HyperParameter set\n",
            "Model: \"127-max-2-0-1580359270\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_8 (InputLayer)            (None, 24, 24, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_489 (Conv2D)             (None, 24, 24, 32)   320         input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_489 (Activation)     (None, 24, 24, 32)   0           conv2d_489[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_490 (Conv2D)             (None, 22, 22, 32)   9248        activation_489[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_490 (Activation)     (None, 22, 22, 32)   0           conv2d_490[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_186 (MaxPooling2D (None, 22, 22, 32)   0           activation_489[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_112 (Concatenate)   (None, 22, 22, 64)   0           activation_490[0][0]             \n",
            "                                                                 max_pooling2d_186[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_494 (Conv2D)             (None, 22, 22, 16)   1040        concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_494 (Activation)     (None, 22, 22, 16)   0           conv2d_494[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_492 (Conv2D)             (None, 22, 22, 64)   4160        concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_495 (Conv2D)             (None, 22, 22, 48)   6960        activation_494[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_492 (Activation)     (None, 22, 22, 64)   0           conv2d_492[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_495 (Activation)     (None, 22, 22, 48)   0           conv2d_495[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_187 (MaxPooling2D (None, 22, 22, 64)   0           concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_491 (Conv2D)             (None, 22, 22, 64)   4160        concatenate_112[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_493 (Conv2D)             (None, 22, 22, 96)   55392       activation_492[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_496 (Conv2D)             (None, 22, 22, 48)   20784       activation_495[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_497 (Conv2D)             (None, 22, 22, 32)   2080        max_pooling2d_187[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_491 (Activation)     (None, 22, 22, 64)   0           conv2d_491[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_493 (Activation)     (None, 22, 22, 96)   0           conv2d_493[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_496 (Activation)     (None, 22, 22, 48)   0           conv2d_496[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_497 (Activation)     (None, 22, 22, 32)   0           conv2d_497[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_113 (Concatenate)   (None, 22, 22, 240)  0           activation_491[0][0]             \n",
            "                                                                 activation_493[0][0]             \n",
            "                                                                 activation_496[0][0]             \n",
            "                                                                 activation_497[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_498 (Conv2D)             (None, 10, 10, 64)   138304      concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_498 (Activation)     (None, 10, 10, 64)   0           conv2d_498[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_188 (MaxPooling2D (None, 10, 10, 240)  0           concatenate_113[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_114 (Concatenate)   (None, 10, 10, 304)  0           activation_498[0][0]             \n",
            "                                                                 max_pooling2d_188[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_499 (Conv2D)             (None, 10, 10, 128)  350336      concatenate_114[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_499 (Activation)     (None, 10, 10, 128)  0           conv2d_499[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_500 (Conv2D)             (None, 10, 10, 128)  147584      activation_499[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_500 (Activation)     (None, 10, 10, 128)  0           conv2d_500[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_189 (MaxPooling2D (None, 4, 4, 128)    0           activation_500[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_501 (Conv2D)             (None, 4, 4, 256)    295168      max_pooling2d_189[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_501 (Activation)     (None, 4, 4, 256)    0           conv2d_501[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_502 (Conv2D)             (None, 4, 4, 256)    590080      activation_501[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_502 (Activation)     (None, 4, 4, 256)    0           conv2d_502[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_190 (MaxPooling2D (None, 2, 2, 256)    0           activation_502[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_38 (Gl (None, 256)          0           max_pooling2d_190[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "fc (Dense)                      (None, 1024)         263168      global_average_pooling2d_38[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "fc_relu (Activation)            (None, 1024)         0           fc[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           fc_relu[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Dense)                 (None, 36)           36900       dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,925,684\n",
            "Trainable params: 1,925,684\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Train on 14400 samples, validate on 3600 samples\n",
            "Epoch 1/50\n",
            " - 7s - loss: 2.4960 - acc: 0.2637 - val_loss: 1.4229 - val_acc: 0.5797\n",
            "Epoch 2/50\n",
            " - 4s - loss: 0.4494 - acc: 0.8488 - val_loss: 0.6281 - val_acc: 0.8078\n",
            "Epoch 3/50\n",
            " - 4s - loss: 0.1990 - acc: 0.9353 - val_loss: 0.6006 - val_acc: 0.8189\n",
            "Epoch 4/50\n",
            " - 4s - loss: 0.1291 - acc: 0.9595 - val_loss: 0.5319 - val_acc: 0.8511\n",
            "Epoch 5/50\n",
            " - 4s - loss: 0.0927 - acc: 0.9720 - val_loss: 0.4981 - val_acc: 0.8539\n",
            "Epoch 6/50\n",
            " - 4s - loss: 0.0695 - acc: 0.9783 - val_loss: 0.3713 - val_acc: 0.8906\n",
            "Epoch 7/50\n",
            " - 4s - loss: 0.0507 - acc: 0.9842 - val_loss: 0.3306 - val_acc: 0.9072\n",
            "Epoch 8/50\n",
            " - 4s - loss: 0.0537 - acc: 0.9838 - val_loss: 0.5570 - val_acc: 0.8586\n",
            "Epoch 9/50\n",
            " - 4s - loss: 0.0410 - acc: 0.9873 - val_loss: 0.8165 - val_acc: 0.8419\n",
            "Epoch 10/50\n",
            " - 4s - loss: 0.0355 - acc: 0.9898 - val_loss: 0.5202 - val_acc: 0.8725\n",
            "Epoch 11/50\n",
            " - 4s - loss: 0.0328 - acc: 0.9899 - val_loss: 0.2866 - val_acc: 0.9211\n",
            "Epoch 12/50\n",
            " - 4s - loss: 0.0213 - acc: 0.9940 - val_loss: 0.4552 - val_acc: 0.8806\n",
            "Epoch 13/50\n",
            " - 4s - loss: 0.0300 - acc: 0.9909 - val_loss: 0.2704 - val_acc: 0.9314\n",
            "Epoch 14/50\n",
            " - 4s - loss: 0.0410 - acc: 0.9869 - val_loss: 0.4676 - val_acc: 0.8839\n",
            "Epoch 15/50\n",
            " - 4s - loss: 0.0331 - acc: 0.9895 - val_loss: 0.3950 - val_acc: 0.8919\n",
            "Epoch 16/50\n",
            " - 4s - loss: 0.0206 - acc: 0.9939 - val_loss: 0.6638 - val_acc: 0.8525\n",
            "Epoch 17/50\n",
            " - 4s - loss: 0.0310 - acc: 0.9917 - val_loss: 0.5031 - val_acc: 0.8725\n",
            "Epoch 18/50\n",
            " - 4s - loss: 0.0231 - acc: 0.9923 - val_loss: 0.2998 - val_acc: 0.9169\n",
            "Epoch 19/50\n",
            " - 4s - loss: 0.0223 - acc: 0.9942 - val_loss: 0.2887 - val_acc: 0.9214\n",
            "Epoch 20/50\n",
            " - 4s - loss: 0.0078 - acc: 0.9977 - val_loss: 0.3960 - val_acc: 0.8964\n",
            "Epoch 21/50\n",
            " - 4s - loss: 0.0124 - acc: 0.9969 - val_loss: 0.5746 - val_acc: 0.8686\n",
            "Epoch 22/50\n",
            " - 4s - loss: 0.0189 - acc: 0.9942 - val_loss: 0.5760 - val_acc: 0.8717\n",
            "Epoch 23/50\n",
            " - 4s - loss: 0.0322 - acc: 0.9917 - val_loss: 0.2467 - val_acc: 0.9328\n",
            "Epoch 24/50\n",
            " - 4s - loss: 0.0244 - acc: 0.9933 - val_loss: 0.2020 - val_acc: 0.9436\n",
            "Epoch 25/50\n",
            " - 4s - loss: 0.0150 - acc: 0.9959 - val_loss: 0.7054 - val_acc: 0.8383\n",
            "Epoch 26/50\n",
            " - 4s - loss: 0.0236 - acc: 0.9935 - val_loss: 0.2897 - val_acc: 0.9236\n",
            "Epoch 27/50\n",
            " - 4s - loss: 0.0156 - acc: 0.9952 - val_loss: 0.3523 - val_acc: 0.9083\n",
            "Epoch 28/50\n",
            " - 4s - loss: 0.0115 - acc: 0.9968 - val_loss: 0.2447 - val_acc: 0.9325\n",
            "Epoch 29/50\n",
            " - 4s - loss: 0.0093 - acc: 0.9976 - val_loss: 0.2353 - val_acc: 0.9406\n",
            "Epoch 30/50\n",
            " - 4s - loss: 0.0161 - acc: 0.9965 - val_loss: 0.6383 - val_acc: 0.8522\n",
            "Epoch 31/50\n",
            " - 4s - loss: 0.0289 - acc: 0.9931 - val_loss: 0.5833 - val_acc: 0.8597\n",
            "Epoch 32/50\n",
            " - 4s - loss: 0.0301 - acc: 0.9913 - val_loss: 0.3447 - val_acc: 0.9178\n",
            "Epoch 33/50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ILl47jluIZrE"
      },
      "source": [
        "## Reference\n",
        "Ignatius Wendianto Notonogoro, Jondri, Anditya Arifianto, \"Indonesian License Plate Recognition Using Convolutional Neural Network\", IEEE, Int. Conf. IColCT, 2018."
      ]
    }
  ]
}